{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d2121e-4d7c-49e6-9638-d56e6e47cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score, auc\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3cc8a-3587-47ee-921f-6aafd577bc64",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f8a309-ed3b-45e9-83b5-4867da6d86ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>vacancy_1</th>\n",
       "      <th>vacancy_2</th>\n",
       "      <th>vacancy_3</th>\n",
       "      <th>vacancy_4</th>\n",
       "      <th>vacancy_5</th>\n",
       "      <th>vacancy_6</th>\n",
       "      <th>vacancy_7</th>\n",
       "      <th>vacancy_8</th>\n",
       "      <th>vacancy_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_303</th>\n",
       "      <th>cv_304</th>\n",
       "      <th>cv_305</th>\n",
       "      <th>cv_306</th>\n",
       "      <th>cv_307</th>\n",
       "      <th>cv_308</th>\n",
       "      <th>cv_309</th>\n",
       "      <th>cv_310</th>\n",
       "      <th>cv_311</th>\n",
       "      <th>cv_312</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01692</td>\n",
       "      <td>0.025250</td>\n",
       "      <td>-0.008520</td>\n",
       "      <td>0.03650</td>\n",
       "      <td>-0.010956</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.019550</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.02689</td>\n",
       "      <td>-0.03876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04938</td>\n",
       "      <td>-0.010440</td>\n",
       "      <td>-0.018020</td>\n",
       "      <td>0.04710</td>\n",
       "      <td>-0.045930</td>\n",
       "      <td>0.00759</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.02934</td>\n",
       "      <td>-0.01372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01761</td>\n",
       "      <td>-0.098500</td>\n",
       "      <td>-0.032840</td>\n",
       "      <td>0.03350</td>\n",
       "      <td>-0.033200</td>\n",
       "      <td>0.03310</td>\n",
       "      <td>-0.006780</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.05340</td>\n",
       "      <td>-0.04110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01761</td>\n",
       "      <td>-0.098500</td>\n",
       "      <td>-0.032840</td>\n",
       "      <td>0.03350</td>\n",
       "      <td>-0.033200</td>\n",
       "      <td>0.03310</td>\n",
       "      <td>-0.006780</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.05340</td>\n",
       "      <td>-0.04110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03790</td>\n",
       "      <td>-0.015850</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>0.03073</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.03500</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.02356</td>\n",
       "      <td>-0.02785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05750</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>0.05573</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.01102</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>0.05704</td>\n",
       "      <td>-0.06415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03412</td>\n",
       "      <td>-0.012344</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.02478</td>\n",
       "      <td>-0.027390</td>\n",
       "      <td>0.01962</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>0.03040</td>\n",
       "      <td>-0.04514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00794</td>\n",
       "      <td>0.022840</td>\n",
       "      <td>-0.005898</td>\n",
       "      <td>0.04590</td>\n",
       "      <td>-0.021710</td>\n",
       "      <td>0.04556</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>-0.06730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02246</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>-0.030490</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.041780</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>-0.03500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>-0.02373</td>\n",
       "      <td>-0.06018</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03732</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>-0.014610</td>\n",
       "      <td>0.02638</td>\n",
       "      <td>-0.018920</td>\n",
       "      <td>0.05264</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.02286</td>\n",
       "      <td>-0.04240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  vacancy_1  vacancy_2  vacancy_3  vacancy_4  vacancy_5  vacancy_6  \\\n",
       "0     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "1     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "2     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "3     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "4     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "5     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "6     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "7     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "8     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "9     0.0       0.07   0.003983    0.02249    -0.0743    0.00631    0.01775   \n",
       "\n",
       "   vacancy_7  vacancy_8  vacancy_9  ...   cv_303    cv_304    cv_305   cv_306  \\\n",
       "0   -0.02373   -0.06018     0.0415  ...  0.01692  0.025250 -0.008520  0.03650   \n",
       "1   -0.02373   -0.06018     0.0415  ...  0.04938 -0.010440 -0.018020  0.04710   \n",
       "2   -0.02373   -0.06018     0.0415  ...  0.01761 -0.098500 -0.032840  0.03350   \n",
       "3   -0.02373   -0.06018     0.0415  ...  0.01761 -0.098500 -0.032840  0.03350   \n",
       "4   -0.02373   -0.06018     0.0415  ...  0.03790 -0.015850 -0.001335  0.03073   \n",
       "5   -0.02373   -0.06018     0.0415  ...  0.05750  0.014595 -0.049870  0.05573   \n",
       "6   -0.02373   -0.06018     0.0415  ...  0.03412 -0.012344 -0.010000  0.02478   \n",
       "7   -0.02373   -0.06018     0.0415  ...  0.00794  0.022840 -0.005898  0.04590   \n",
       "8   -0.02373   -0.06018     0.0415  ...  0.02246 -0.023200 -0.006380  0.07680   \n",
       "9   -0.02373   -0.06018     0.0415  ...  0.03732 -0.013960 -0.014610  0.02638   \n",
       "\n",
       "     cv_307   cv_308    cv_309    cv_310   cv_311   cv_312  \n",
       "0 -0.010956  0.03540  0.019550  0.007103  0.02689 -0.03876  \n",
       "1 -0.045930  0.00759  0.013050  0.010750  0.02934 -0.01372  \n",
       "2 -0.033200  0.03310 -0.006780  0.051000  0.05340 -0.04110  \n",
       "3 -0.033200  0.03310 -0.006780  0.051000  0.05340 -0.04110  \n",
       "4  0.002558  0.03500  0.021400  0.032040  0.02356 -0.02785  \n",
       "5  0.019960  0.01102  0.029950 -0.023220  0.05704 -0.06415  \n",
       "6 -0.027390  0.01962 -0.002752 -0.004390  0.03040 -0.04514  \n",
       "7 -0.021710  0.04556  0.018650  0.020540  0.01800 -0.06730  \n",
       "8 -0.030490  0.04500  0.036740  0.041780  0.02174 -0.03500  \n",
       "9 -0.018920  0.05264  0.007202  0.027040  0.02286 -0.04240  \n",
       "\n",
       "[10 rows x 625 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH + 'light_prepared_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e178857e-ffe2-45a0-8f4b-3c8872791c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64334, 625)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda4f720-fe2c-4157-93a4-b7531f8a9ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_1</th>\n",
       "      <th>vacancy_2</th>\n",
       "      <th>vacancy_3</th>\n",
       "      <th>vacancy_4</th>\n",
       "      <th>vacancy_5</th>\n",
       "      <th>vacancy_6</th>\n",
       "      <th>vacancy_7</th>\n",
       "      <th>vacancy_8</th>\n",
       "      <th>vacancy_9</th>\n",
       "      <th>vacancy_10</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_303</th>\n",
       "      <th>cv_304</th>\n",
       "      <th>cv_305</th>\n",
       "      <th>cv_306</th>\n",
       "      <th>cv_307</th>\n",
       "      <th>cv_308</th>\n",
       "      <th>cv_309</th>\n",
       "      <th>cv_310</th>\n",
       "      <th>cv_311</th>\n",
       "      <th>cv_312</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33415</th>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.08240</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>-0.10040</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>-0.04420</td>\n",
       "      <td>-0.02539</td>\n",
       "      <td>-0.019490</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02246</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>-0.03049</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.041780</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>-0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51516</th>\n",
       "      <td>0.08936</td>\n",
       "      <td>0.08470</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-0.08923</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>-0.03280</td>\n",
       "      <td>-0.01189</td>\n",
       "      <td>-0.012540</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01312</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.017230</td>\n",
       "      <td>0.07556</td>\n",
       "      <td>-0.00489</td>\n",
       "      <td>0.02467</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.041870</td>\n",
       "      <td>-0.034900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>0.01804</td>\n",
       "      <td>0.05457</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>-0.07590</td>\n",
       "      <td>-0.005672</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>-0.02345</td>\n",
       "      <td>-0.06168</td>\n",
       "      <td>-0.003038</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04828</td>\n",
       "      <td>-0.065800</td>\n",
       "      <td>-0.027500</td>\n",
       "      <td>0.03650</td>\n",
       "      <td>-0.06396</td>\n",
       "      <td>0.07630</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>-0.007996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23688</th>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>-0.07367</td>\n",
       "      <td>-0.039030</td>\n",
       "      <td>0.069640</td>\n",
       "      <td>-0.07600</td>\n",
       "      <td>-0.11597</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>-0.01753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04590</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-0.027400</td>\n",
       "      <td>0.07740</td>\n",
       "      <td>-0.00573</td>\n",
       "      <td>0.03041</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>0.047030</td>\n",
       "      <td>-0.025340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21265</th>\n",
       "      <td>0.03778</td>\n",
       "      <td>0.02924</td>\n",
       "      <td>0.007484</td>\n",
       "      <td>-0.06980</td>\n",
       "      <td>-0.036200</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>-0.07420</td>\n",
       "      <td>-0.10815</td>\n",
       "      <td>0.015076</td>\n",
       "      <td>-0.01324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04578</td>\n",
       "      <td>0.017580</td>\n",
       "      <td>-0.025800</td>\n",
       "      <td>0.04630</td>\n",
       "      <td>-0.04820</td>\n",
       "      <td>0.02083</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.048520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>0.05576</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>-0.06494</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>-0.016660</td>\n",
       "      <td>-0.04105</td>\n",
       "      <td>-0.06168</td>\n",
       "      <td>0.028440</td>\n",
       "      <td>0.03912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05038</td>\n",
       "      <td>-0.016830</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>0.04324</td>\n",
       "      <td>-0.03060</td>\n",
       "      <td>0.01133</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>-0.038820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27810</th>\n",
       "      <td>0.05630</td>\n",
       "      <td>0.03464</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>-0.06976</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>-0.05927</td>\n",
       "      <td>-0.07840</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.01143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01036</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.01900</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.03156</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>-0.005970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46969</th>\n",
       "      <td>0.06110</td>\n",
       "      <td>0.06930</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>-0.08890</td>\n",
       "      <td>0.013490</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>-0.02826</td>\n",
       "      <td>-0.02048</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01721</td>\n",
       "      <td>-0.044430</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>0.01935</td>\n",
       "      <td>-0.03513</td>\n",
       "      <td>0.03375</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>-0.059540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41202</th>\n",
       "      <td>0.05417</td>\n",
       "      <td>0.07750</td>\n",
       "      <td>0.030780</td>\n",
       "      <td>-0.10410</td>\n",
       "      <td>0.015820</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>-0.02666</td>\n",
       "      <td>-0.02255</td>\n",
       "      <td>-0.030120</td>\n",
       "      <td>0.05112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06930</td>\n",
       "      <td>-0.026320</td>\n",
       "      <td>-0.032960</td>\n",
       "      <td>0.06793</td>\n",
       "      <td>-0.02266</td>\n",
       "      <td>0.03458</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>-0.009705</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>-0.032870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18459</th>\n",
       "      <td>0.09640</td>\n",
       "      <td>0.05414</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>-0.08655</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>-0.04922</td>\n",
       "      <td>-0.02646</td>\n",
       "      <td>-0.012680</td>\n",
       "      <td>0.03180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.026370</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.05480</td>\n",
       "      <td>-0.02377</td>\n",
       "      <td>0.02441</td>\n",
       "      <td>-0.015690</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>-0.025180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vacancy_1  vacancy_2  vacancy_3  vacancy_4  vacancy_5  vacancy_6  \\\n",
       "33415    0.06250    0.08240   0.037000   -0.10040  -0.009476   0.015990   \n",
       "51516    0.08936    0.08470   0.021840   -0.08923   0.014070   0.004345   \n",
       "9774     0.01804    0.05457   0.038760   -0.07590  -0.005672   0.024030   \n",
       "23688    0.04364    0.02667   0.004640   -0.07367  -0.039030   0.069640   \n",
       "21265    0.03778    0.02924   0.007484   -0.06980  -0.036200   0.055270   \n",
       "41993    0.05576    0.06570   0.034800   -0.06494   0.011810  -0.016660   \n",
       "27810    0.05630    0.03464   0.042880   -0.06976  -0.000862   0.000509   \n",
       "46969    0.06110    0.06930   0.030800   -0.08890   0.013490   0.024540   \n",
       "41202    0.05417    0.07750   0.030780   -0.10410   0.015820   0.007770   \n",
       "18459    0.09640    0.05414   0.028320   -0.08655   0.020300   0.030440   \n",
       "\n",
       "       vacancy_7  vacancy_8  vacancy_9  vacancy_10  ...   cv_303    cv_304  \\\n",
       "33415   -0.04420   -0.02539  -0.019490     0.02250  ...  0.02246 -0.023200   \n",
       "51516   -0.03280   -0.01189  -0.012540     0.04996  ...  0.01312 -0.000911   \n",
       "9774    -0.02345   -0.06168  -0.003038     0.02925  ...  0.04828 -0.065800   \n",
       "23688   -0.07600   -0.11597   0.009575    -0.01753  ...  0.04590 -0.010190   \n",
       "21265   -0.07420   -0.10815   0.015076    -0.01324  ...  0.04578  0.017580   \n",
       "41993   -0.04105   -0.06168   0.028440     0.03912  ...  0.05038 -0.016830   \n",
       "27810   -0.05927   -0.07840   0.023800     0.01143  ...  0.01036  0.018620   \n",
       "46969   -0.02826   -0.02048   0.001670     0.03574  ...  0.01721 -0.044430   \n",
       "41202   -0.02666   -0.02255  -0.030120     0.05112  ...  0.06930 -0.026320   \n",
       "18459   -0.04922   -0.02646  -0.012680     0.03180  ...  0.02168  0.026370   \n",
       "\n",
       "         cv_305   cv_306   cv_307   cv_308    cv_309    cv_310    cv_311  \\\n",
       "33415 -0.006380  0.07680 -0.03049  0.04500  0.036740  0.041780  0.021740   \n",
       "51516 -0.017230  0.07556 -0.00489  0.02467  0.012540  0.008446  0.041870   \n",
       "9774  -0.027500  0.03650 -0.06396  0.07630  0.005905  0.024750  0.040650   \n",
       "23688 -0.027400  0.07740 -0.00573  0.03041 -0.001741  0.020430  0.047030   \n",
       "21265 -0.025800  0.04630 -0.04820  0.02083  0.001442  0.021330  0.050000   \n",
       "41993 -0.016000  0.04324 -0.03060  0.01133  0.025040  0.006065  0.045900   \n",
       "27810  0.014080  0.01900  0.03244  0.03156 -0.003233  0.081800  0.006237   \n",
       "46969 -0.000669  0.01935 -0.03513  0.03375  0.014435  0.030440  0.039920   \n",
       "41202 -0.032960  0.06793 -0.02266  0.03458  0.043400 -0.009705  0.056400   \n",
       "18459 -0.000685  0.05480 -0.02377  0.02441 -0.015690  0.036650  0.042000   \n",
       "\n",
       "         cv_312  \n",
       "33415 -0.035000  \n",
       "51516 -0.034900  \n",
       "9774  -0.007996  \n",
       "23688 -0.025340  \n",
       "21265 -0.048520  \n",
       "41993 -0.038820  \n",
       "27810 -0.005970  \n",
       "46969 -0.059540  \n",
       "41202 -0.032870  \n",
       "18459 -0.025180  \n",
       "\n",
       "[10 rows x 624 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(columns=['target']), df['target']\n",
    "X_fulltrain, X_test, y_fulltrain, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_fulltrain, y_fulltrain, test_size=0.2, random_state=42, stratify=y_fulltrain)\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6abf64-c2ce-494a-a269-ef3c3a35374a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_1</th>\n",
       "      <th>vacancy_2</th>\n",
       "      <th>vacancy_3</th>\n",
       "      <th>vacancy_4</th>\n",
       "      <th>vacancy_5</th>\n",
       "      <th>vacancy_6</th>\n",
       "      <th>vacancy_7</th>\n",
       "      <th>vacancy_8</th>\n",
       "      <th>vacancy_9</th>\n",
       "      <th>vacancy_10</th>\n",
       "      <th>...</th>\n",
       "      <th>vacancy_303</th>\n",
       "      <th>vacancy_304</th>\n",
       "      <th>vacancy_305</th>\n",
       "      <th>vacancy_306</th>\n",
       "      <th>vacancy_307</th>\n",
       "      <th>vacancy_308</th>\n",
       "      <th>vacancy_309</th>\n",
       "      <th>vacancy_310</th>\n",
       "      <th>vacancy_311</th>\n",
       "      <th>vacancy_312</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59089</th>\n",
       "      <td>0.05386</td>\n",
       "      <td>0.00595</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>-0.03473</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.02605</td>\n",
       "      <td>-0.03330</td>\n",
       "      <td>-0.10114</td>\n",
       "      <td>-0.004660</td>\n",
       "      <td>-0.00904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049220</td>\n",
       "      <td>-0.01845</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>0.027180</td>\n",
       "      <td>0.02303</td>\n",
       "      <td>-0.002884</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>-0.007053</td>\n",
       "      <td>-0.016570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22952</th>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>-0.07367</td>\n",
       "      <td>-0.039030</td>\n",
       "      <td>0.06964</td>\n",
       "      <td>-0.07600</td>\n",
       "      <td>-0.11597</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>-0.01753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>-0.00495</td>\n",
       "      <td>-0.003304</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.01952</td>\n",
       "      <td>-0.002447</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.029660</td>\n",
       "      <td>-0.003035</td>\n",
       "      <td>-0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>-0.07367</td>\n",
       "      <td>-0.039030</td>\n",
       "      <td>0.06964</td>\n",
       "      <td>-0.07600</td>\n",
       "      <td>-0.11597</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>-0.01753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>-0.00495</td>\n",
       "      <td>-0.003304</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.01952</td>\n",
       "      <td>-0.002447</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.029660</td>\n",
       "      <td>-0.003035</td>\n",
       "      <td>-0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31173</th>\n",
       "      <td>0.06660</td>\n",
       "      <td>0.02333</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>-0.04755</td>\n",
       "      <td>-0.017850</td>\n",
       "      <td>0.03506</td>\n",
       "      <td>-0.04230</td>\n",
       "      <td>-0.04020</td>\n",
       "      <td>0.030080</td>\n",
       "      <td>-0.01146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006740</td>\n",
       "      <td>-0.04218</td>\n",
       "      <td>-0.011510</td>\n",
       "      <td>-0.010920</td>\n",
       "      <td>0.04742</td>\n",
       "      <td>0.039950</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.039860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10651</th>\n",
       "      <td>0.02072</td>\n",
       "      <td>0.05154</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>-0.09360</td>\n",
       "      <td>-0.019170</td>\n",
       "      <td>0.05545</td>\n",
       "      <td>-0.05304</td>\n",
       "      <td>-0.10140</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>-0.01261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>-0.03357</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>-0.02478</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.031770</td>\n",
       "      <td>-0.009140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>0.07640</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.10645</td>\n",
       "      <td>0.024550</td>\n",
       "      <td>0.01874</td>\n",
       "      <td>-0.01997</td>\n",
       "      <td>-0.04044</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.02316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>-0.06880</td>\n",
       "      <td>-0.013640</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.00901</td>\n",
       "      <td>0.040130</td>\n",
       "      <td>-0.005802</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.024570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54450</th>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.02760</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>-0.08310</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.06775</td>\n",
       "      <td>-0.06430</td>\n",
       "      <td>-0.07837</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>-0.02757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046840</td>\n",
       "      <td>-0.01779</td>\n",
       "      <td>-0.008760</td>\n",
       "      <td>-0.006813</td>\n",
       "      <td>-0.01646</td>\n",
       "      <td>-0.020050</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>-0.002916</td>\n",
       "      <td>-0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58225</th>\n",
       "      <td>0.05502</td>\n",
       "      <td>0.03052</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>-0.08630</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.02588</td>\n",
       "      <td>-0.01416</td>\n",
       "      <td>-0.07250</td>\n",
       "      <td>0.023650</td>\n",
       "      <td>0.05250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>-0.04210</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.027220</td>\n",
       "      <td>-0.01041</td>\n",
       "      <td>0.023570</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>0.052670</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>-0.013120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44788</th>\n",
       "      <td>0.13200</td>\n",
       "      <td>0.00549</td>\n",
       "      <td>0.032260</td>\n",
       "      <td>-0.01209</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>-0.04410</td>\n",
       "      <td>-0.06128</td>\n",
       "      <td>-0.07574</td>\n",
       "      <td>-0.008060</td>\n",
       "      <td>0.04443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>-0.07434</td>\n",
       "      <td>-0.028380</td>\n",
       "      <td>-0.026960</td>\n",
       "      <td>-0.01111</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.020520</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39774</th>\n",
       "      <td>0.04172</td>\n",
       "      <td>0.06024</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>-0.10724</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.01866</td>\n",
       "      <td>-0.01374</td>\n",
       "      <td>-0.02667</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>-0.05444</td>\n",
       "      <td>-0.010960</td>\n",
       "      <td>-0.002214</td>\n",
       "      <td>-0.03770</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>-0.018660</td>\n",
       "      <td>0.018250</td>\n",
       "      <td>0.080440</td>\n",
       "      <td>-0.007416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12867 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vacancy_1  vacancy_2  vacancy_3  vacancy_4  vacancy_5  vacancy_6  \\\n",
       "59089    0.05386    0.00595   0.038330   -0.03473   0.004707   -0.02605   \n",
       "22952    0.04364    0.02667   0.004640   -0.07367  -0.039030    0.06964   \n",
       "24997    0.04364    0.02667   0.004640   -0.07367  -0.039030    0.06964   \n",
       "31173    0.06660    0.02333   0.010530   -0.04755  -0.017850    0.03506   \n",
       "10651    0.02072    0.05154   0.006813   -0.09360  -0.019170    0.05545   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "4124     0.07640    0.09350   0.035860   -0.10645   0.024550    0.01874   \n",
       "54450    0.04920    0.02760   0.003057   -0.08310   0.003899    0.06775   \n",
       "58225    0.05502    0.03052   0.050800   -0.08630   0.007990    0.02588   \n",
       "44788    0.13200    0.00549   0.032260   -0.01209   0.024630   -0.04410   \n",
       "39774    0.04172    0.06024   0.053100   -0.10724   0.035060    0.01866   \n",
       "\n",
       "       vacancy_7  vacancy_8  vacancy_9  vacancy_10  ...  vacancy_303  \\\n",
       "59089   -0.03330   -0.10114  -0.004660    -0.00904  ...     0.049220   \n",
       "22952   -0.07600   -0.11597   0.009575    -0.01753  ...     0.010970   \n",
       "24997   -0.07600   -0.11597   0.009575    -0.01753  ...     0.010970   \n",
       "31173   -0.04230   -0.04020   0.030080    -0.01146  ...    -0.006740   \n",
       "10651   -0.05304   -0.10140  -0.002304    -0.01261  ...     0.001428   \n",
       "...          ...        ...        ...         ...  ...          ...   \n",
       "4124    -0.01997   -0.04044  -0.002531     0.02316  ...     0.028020   \n",
       "54450   -0.06430   -0.07837   0.011910    -0.02757  ...     0.046840   \n",
       "58225   -0.01416   -0.07250   0.023650     0.05250  ...     0.031460   \n",
       "44788   -0.06128   -0.07574  -0.008060     0.04443  ...     0.071300   \n",
       "39774   -0.01374   -0.02667   0.003080     0.04562  ...     0.040200   \n",
       "\n",
       "       vacancy_304  vacancy_305  vacancy_306  vacancy_307  vacancy_308  \\\n",
       "59089     -0.01845     0.015990     0.027180      0.02303    -0.002884   \n",
       "22952     -0.00495    -0.003304    -0.001562      0.01952    -0.002447   \n",
       "24997     -0.00495    -0.003304    -0.001562      0.01952    -0.002447   \n",
       "31173     -0.04218    -0.011510    -0.010920      0.04742     0.039950   \n",
       "10651     -0.03357     0.031170     0.006275     -0.02478     0.003880   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "4124      -0.06880    -0.013640     0.017840      0.00901     0.040130   \n",
       "54450     -0.01779    -0.008760    -0.006813     -0.01646    -0.020050   \n",
       "58225     -0.04210    -0.000628    -0.027220     -0.01041     0.023570   \n",
       "44788     -0.07434    -0.028380    -0.026960     -0.01111     0.052600   \n",
       "39774     -0.05444    -0.010960    -0.002214     -0.03770     0.042270   \n",
       "\n",
       "       vacancy_309  vacancy_310  vacancy_311  vacancy_312  \n",
       "59089     0.008770     0.055300    -0.007053    -0.016570  \n",
       "22952     0.045750     0.029660    -0.003035    -0.061300  \n",
       "24997     0.045750     0.029660    -0.003035    -0.061300  \n",
       "31173     0.044460     0.006905    -0.000990    -0.039860  \n",
       "10651     0.019990     0.060300     0.031770    -0.009140  \n",
       "...            ...          ...          ...          ...  \n",
       "4124     -0.005802     0.066300     0.070400     0.024570  \n",
       "54450    -0.000132     0.011220    -0.002916    -0.097100  \n",
       "58225    -0.000687     0.052670     0.073900    -0.013120  \n",
       "44788     0.021090     0.020520     0.061800     0.003557  \n",
       "39774    -0.018660     0.018250     0.080440    -0.007416  \n",
       "\n",
       "[12867 rows x 312 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[:, :312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68135a2a-9562-43a0-8cff-fbe7ded72a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_1</th>\n",
       "      <th>cv_2</th>\n",
       "      <th>cv_3</th>\n",
       "      <th>cv_4</th>\n",
       "      <th>cv_5</th>\n",
       "      <th>cv_6</th>\n",
       "      <th>cv_7</th>\n",
       "      <th>cv_8</th>\n",
       "      <th>cv_9</th>\n",
       "      <th>cv_10</th>\n",
       "      <th>...</th>\n",
       "      <th>cv_303</th>\n",
       "      <th>cv_304</th>\n",
       "      <th>cv_305</th>\n",
       "      <th>cv_306</th>\n",
       "      <th>cv_307</th>\n",
       "      <th>cv_308</th>\n",
       "      <th>cv_309</th>\n",
       "      <th>cv_310</th>\n",
       "      <th>cv_311</th>\n",
       "      <th>cv_312</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59089</th>\n",
       "      <td>0.113650</td>\n",
       "      <td>-0.02655</td>\n",
       "      <td>-0.02954</td>\n",
       "      <td>-0.05160</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>-0.011665</td>\n",
       "      <td>0.04180</td>\n",
       "      <td>-0.06177</td>\n",
       "      <td>0.013970</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.043370</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.04117</td>\n",
       "      <td>-0.043060</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>-0.061830</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.037380</td>\n",
       "      <td>-0.01901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22952</th>\n",
       "      <td>-0.028100</td>\n",
       "      <td>0.08374</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>-0.10785</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>-0.04633</td>\n",
       "      <td>-0.06550</td>\n",
       "      <td>-0.010130</td>\n",
       "      <td>-0.055050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.03082</td>\n",
       "      <td>0.050170</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>0.08730</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>-0.08890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.03710</td>\n",
       "      <td>0.03360</td>\n",
       "      <td>-0.09980</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.01775</td>\n",
       "      <td>0.01098</td>\n",
       "      <td>-0.058600</td>\n",
       "      <td>0.023510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>-0.075260</td>\n",
       "      <td>-0.002537</td>\n",
       "      <td>0.05212</td>\n",
       "      <td>-0.038120</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>-0.009605</td>\n",
       "      <td>0.03394</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>0.01347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31173</th>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.00367</td>\n",
       "      <td>-0.02296</td>\n",
       "      <td>-0.04425</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>-0.030320</td>\n",
       "      <td>-0.04610</td>\n",
       "      <td>-0.03890</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.041080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>-0.014800</td>\n",
       "      <td>0.05002</td>\n",
       "      <td>-0.039830</td>\n",
       "      <td>0.050050</td>\n",
       "      <td>0.020970</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>-0.02560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10651</th>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.02115</td>\n",
       "      <td>-0.04280</td>\n",
       "      <td>-0.09850</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>-0.03047</td>\n",
       "      <td>-0.08984</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.01726</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>-0.02365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>0.078700</td>\n",
       "      <td>-0.04320</td>\n",
       "      <td>-0.03992</td>\n",
       "      <td>-0.04156</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>-0.04530</td>\n",
       "      <td>-0.07355</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>0.05573</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>-0.02322</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>-0.06415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54450</th>\n",
       "      <td>0.107240</td>\n",
       "      <td>0.01622</td>\n",
       "      <td>0.00820</td>\n",
       "      <td>-0.03796</td>\n",
       "      <td>0.048650</td>\n",
       "      <td>-0.020970</td>\n",
       "      <td>-0.01866</td>\n",
       "      <td>-0.04364</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.045170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>-0.036680</td>\n",
       "      <td>-0.012856</td>\n",
       "      <td>0.01735</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.034240</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.03070</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>-0.03006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58225</th>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.04794</td>\n",
       "      <td>0.01387</td>\n",
       "      <td>-0.06366</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.021590</td>\n",
       "      <td>-0.03928</td>\n",
       "      <td>-0.04083</td>\n",
       "      <td>-0.003613</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022460</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>-0.030490</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.04178</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>-0.03500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44788</th>\n",
       "      <td>0.056980</td>\n",
       "      <td>0.02307</td>\n",
       "      <td>-0.01330</td>\n",
       "      <td>-0.03460</td>\n",
       "      <td>0.019910</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>-0.03800</td>\n",
       "      <td>-0.06300</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.025540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>0.05417</td>\n",
       "      <td>-0.027330</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.020160</td>\n",
       "      <td>0.02115</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>-0.03360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39774</th>\n",
       "      <td>0.109740</td>\n",
       "      <td>0.02304</td>\n",
       "      <td>0.04910</td>\n",
       "      <td>-0.02213</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>-0.040130</td>\n",
       "      <td>-0.01883</td>\n",
       "      <td>-0.07620</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.051450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>-0.021770</td>\n",
       "      <td>-0.02320</td>\n",
       "      <td>-0.011406</td>\n",
       "      <td>0.041470</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.03730</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>-0.02135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12867 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cv_1     cv_2     cv_3     cv_4      cv_5      cv_6     cv_7  \\\n",
       "59089  0.113650 -0.02655 -0.02954 -0.05160  0.035370 -0.011665  0.04180   \n",
       "22952 -0.028100  0.08374  0.00997 -0.10785  0.006145  0.029240 -0.04633   \n",
       "24997 -0.000939  0.03710  0.03360 -0.09980  0.005547 -0.004856 -0.01775   \n",
       "31173  0.099240  0.00367 -0.02296 -0.04425  0.043100 -0.030320 -0.04610   \n",
       "10651  0.045750  0.02115 -0.04280 -0.09850  0.041700  0.004760 -0.03047   \n",
       "...         ...      ...      ...      ...       ...       ...      ...   \n",
       "4124   0.078700 -0.04320 -0.03992 -0.04156  0.024810 -0.001302 -0.04530   \n",
       "54450  0.107240  0.01622  0.00820 -0.03796  0.048650 -0.020970 -0.01866   \n",
       "58225  0.050500  0.04794  0.01387 -0.06366  0.012344  0.021590 -0.03928   \n",
       "44788  0.056980  0.02307 -0.01330 -0.03460  0.019910  0.003090 -0.03800   \n",
       "39774  0.109740  0.02304  0.04910 -0.02213  0.008280 -0.040130 -0.01883   \n",
       "\n",
       "          cv_8      cv_9     cv_10  ...    cv_303    cv_304    cv_305  \\\n",
       "59089 -0.06177  0.013970  0.085940  ...  0.010635  0.043370  0.017760   \n",
       "22952 -0.06550 -0.010130 -0.055050  ... -0.006330  0.060120  0.000777   \n",
       "24997  0.01098 -0.058600  0.023510  ...  0.030700 -0.075260 -0.002537   \n",
       "31173 -0.03890  0.016300  0.041080  ...  0.043640  0.006370 -0.014800   \n",
       "10651 -0.08984  0.000144  0.001643  ...  0.004963  0.019710  0.028000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4124  -0.07355  0.055400  0.000456  ...  0.057500  0.014595 -0.049870   \n",
       "54450 -0.04364  0.015015  0.045170  ...  0.019710 -0.036680 -0.012856   \n",
       "58225 -0.04083 -0.003613  0.038200  ...  0.022460 -0.023200 -0.006380   \n",
       "44788 -0.06300  0.007170  0.025540  ...  0.062800  0.000734 -0.000538   \n",
       "39774 -0.07620  0.007523  0.051450  ...  0.038500 -0.001884 -0.021770   \n",
       "\n",
       "        cv_306    cv_307    cv_308    cv_309   cv_310    cv_311   cv_312  \n",
       "59089  0.04117 -0.043060  0.012800 -0.061830  0.01593  0.037380 -0.01901  \n",
       "22952  0.03082  0.050170 -0.002548  0.038540  0.08730  0.053900 -0.08890  \n",
       "24997  0.05212 -0.038120  0.060500 -0.009605  0.03394 -0.005714  0.01347  \n",
       "31173  0.05002 -0.039830  0.050050  0.020970  0.02100  0.022230 -0.02560  \n",
       "10651  0.01726  0.007940  0.009094  0.000235  0.05914  0.015090 -0.02365  \n",
       "...        ...       ...       ...       ...      ...       ...      ...  \n",
       "4124   0.05573  0.019960  0.011020  0.029950 -0.02322  0.057040 -0.06415  \n",
       "54450  0.01735  0.011220  0.034240 -0.000201  0.03070  0.010155 -0.03006  \n",
       "58225  0.07680 -0.030490  0.045000  0.036740  0.04178  0.021740 -0.03500  \n",
       "44788  0.05417 -0.027330  0.029940  0.020160  0.02115  0.044280 -0.03360  \n",
       "39774 -0.02320 -0.011406  0.041470  0.007980  0.03730  0.008630 -0.02135  \n",
       "\n",
       "[12867 rows x 312 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[:, 312:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c47a7-343e-412d-9f8f-6664a357348f",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36c26827-6e1a-428d-8ca5-19a41a3f60b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956378611307241"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = cosine_similarity(X_test.iloc[:, :312], X_test.iloc[:, 312:]).diagonal()\n",
    "roc_auc_score(y_true = y_test, y_score = res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c33d7-1f5f-4cbd-89e1-8e816e34143d",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb62d35-74b1-47de-bfb0-0949a43eeae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9149652062512283"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm = svm.LinearSVC(class_weight='balanced', verbose=False, max_iter=10000, tol=1e-6, C=10)\n",
    "clf_svm.fit(X_train, y_train) # train\n",
    "similarities = clf_svm.decision_function(X_test)\n",
    "\n",
    "roc_auc_score(y_true = y_test, y_score = similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817237b-88c6-45e7-b0cb-ccd1611da8e5",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b863c728-13f4-4ebc-8602-c96191cb589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8998438284770092"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ridge = RidgeClassifierCV()\n",
    "clf_ridge.fit(X_train, y_train)\n",
    "similarities = clf_ridge.decision_function(X_test)\n",
    "\n",
    "roc_auc_score(y_test, , average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c50b36-0dc3-4713-8767-f74514b5964a",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5494e7f-0b42-4a4f-8e48-1ee4544b2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(x):\n",
    "    a = np.array(x.iloc[312:])\n",
    "    b = np.array(x.iloc[:312])\n",
    "    return np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e543b456-1e5c-48e2-b907-fef2bd0c56a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956630465639353"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = X_test.apply(dot, axis=1)\n",
    "roc_auc_score(y_test, similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277130d3-b0ae-41fd-83e4-f983a13874b7",
   "metadata": {},
   "source": [
    "### SVM hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25c59820-4c2f-4e94-b275-47dd27c22496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV 2/3] END .....................C=0.1, gamma=1, kernel=rbf; total time=10.3min\n",
      "[CV 1/3] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=31.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ................C=0.1, gamma=0.1, kernel=linear; total time= 9.3min\n",
      "[CV 1/3] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=31.7min\n",
      "[CV 3/3] END ..............C=0.1, gamma=0.001, kernel=linear; total time=12.5min\n",
      "[CV 3/3] END .............C=0.1, gamma=0.0001, kernel=linear; total time=12.6min\n",
      "[CV 2/3] END .....................C=0.5, gamma=1, kernel=rbf; total time=15.5min\n",
      "[CV 1/3] END ...............C=0.5, gamma=0.01, kernel=linear; total time=11.8min\n",
      "[CV 1/3] END ..............C=0.5, gamma=0.001, kernel=linear; total time=11.9min\n",
      "[CV 2/3] END .............C=0.5, gamma=0.0001, kernel=linear; total time=41.5min\n",
      "[CV 1/3] END .......................C=1, gamma=1, kernel=rbf; total time=56.3min\n",
      "[CV 3/3] END .....................C=1, gamma=0.1, kernel=rbf; total time=12.9min\n",
      "[CV 1/3] END ...................C=1, gamma=0.001, kernel=rbf; total time=17.5min\n",
      "[CV 3/3] END ..................C=1, gamma=0.0001, kernel=rbf; total time=17.8min\n",
      "[CV 3/3] END ..................C=5, gamma=0.1, kernel=linear; total time=70.7min\n",
      "[CV 2/3] END ....................C=5, gamma=0.01, kernel=rbf; total time=12.2min\n",
      "[CV 1/3] END ...............C=5, gamma=0.0001, kernel=linear; total time=10.5min\n",
      "[CV 2/3] END ...................C=10, gamma=1, kernel=linear; total time=11.0min\n",
      "[CV 3/3] END .................C=10, gamma=0.1, kernel=linear; total time=11.9min\n",
      "[CV 2/3] END ...................C=10, gamma=0.01, kernel=rbf; total time=29.6min\n",
      "[CV 3/3] END ..................C=10, gamma=0.001, kernel=rbf; total time=13.9min\n",
      "[CV 2/3] END .....................C=100, gamma=1, kernel=rbf; total time=11.5min\n",
      "[CV 1/3] END ...............C=100, gamma=0.01, kernel=linear; total time=11.5min\n",
      "[CV 2/3] END ..............C=100, gamma=0.001, kernel=linear; total time=11.0min\n",
      "[CV 2/3] END .............C=100, gamma=0.0001, kernel=linear; total time=11.5min\n",
      "[CV 2/3] END ..................C=0.1, gamma=1, kernel=linear; total time= 9.4min\n",
      "[CV 1/3] END ...............C=0.1, gamma=0.01, kernel=linear; total time=13.6min\n",
      "[CV 3/3] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=31.9min\n",
      "[CV 2/3] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=16.0min\n",
      "[CV 2/3] END ................C=0.5, gamma=0.1, kernel=linear; total time=12.2min\n",
      "[CV 2/3] END ...............C=0.5, gamma=0.01, kernel=linear; total time=11.8min\n",
      "[CV 3/3] END ..............C=0.5, gamma=0.001, kernel=linear; total time=12.0min\n",
      "[CV 3/3] END .............C=0.5, gamma=0.0001, kernel=linear; total time=56.2min\n",
      "[CV 2/3] END .......................C=1, gamma=1, kernel=rbf; total time=41.4min\n",
      "[CV 1/3] END .................C=1, gamma=0.01, kernel=linear; total time= 9.7min\n",
      "[CV 2/3] END ................C=1, gamma=0.001, kernel=linear; total time=12.5min\n",
      "[CV 2/3] END ...............C=1, gamma=0.0001, kernel=linear; total time=13.9min\n",
      "[CV 1/3] END .......................C=5, gamma=1, kernel=rbf; total time=29.8min\n",
      "[CV 3/3] END .....................C=5, gamma=0.1, kernel=rbf; total time=55.3min\n",
      "[CV 3/3] END ................C=5, gamma=0.001, kernel=linear; total time= 9.9min\n",
      "[CV 3/3] END ...............C=5, gamma=0.0001, kernel=linear; total time=10.7min\n",
      "[CV 1/3] END ......................C=10, gamma=1, kernel=rbf; total time=12.0min\n",
      "[CV 3/3] END ....................C=10, gamma=0.1, kernel=rbf; total time=15.2min\n",
      "[CV 3/3] END ...............C=10, gamma=0.001, kernel=linear; total time=26.1min\n",
      "[CV 2/3] END .................C=10, gamma=0.0001, kernel=rbf; total time=14.6min\n",
      "[CV 1/3] END ................C=100, gamma=0.1, kernel=linear; total time=11.2min\n",
      "[CV 3/3] END ...............C=100, gamma=0.01, kernel=linear; total time=11.3min\n",
      "[CV 1/3] END .................C=100, gamma=0.001, kernel=rbf; total time=15.4min\n",
      "[CV 3/3] END ................C=100, gamma=0.0001, kernel=rbf; total time=23.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ................C=0.1, gamma=0.1, kernel=linear; total time= 9.4min\n",
      "[CV 3/3] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=31.6min\n",
      "[CV 1/3] END .................C=0.1, gamma=0.001, kernel=rbf; total time=15.7min\n",
      "[CV 3/3] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=16.2min\n",
      "[CV 3/3] END ................C=0.5, gamma=0.1, kernel=linear; total time=12.4min\n",
      "[CV 2/3] END ..................C=0.5, gamma=0.01, kernel=rbf; total time=15.7min\n",
      "[CV 1/3] END .............C=0.5, gamma=0.0001, kernel=linear; total time=26.5min\n",
      "[CV 2/3] END ....................C=1, gamma=1, kernel=linear; total time=69.9min\n",
      "[CV 3/3] END ..................C=1, gamma=0.1, kernel=linear; total time= 9.4min\n",
      "[CV 1/3] END ....................C=1, gamma=0.01, kernel=rbf; total time=15.0min\n",
      "[CV 3/3] END ...................C=1, gamma=0.001, kernel=rbf; total time=18.0min\n",
      "[CV 3/3] END ....................C=5, gamma=1, kernel=linear; total time=13.1min\n",
      "[CV 2/3] END .....................C=5, gamma=0.1, kernel=rbf; total time=71.0min\n",
      "[CV 3/3] END ....................C=5, gamma=0.01, kernel=rbf; total time=12.9min\n",
      "[CV 2/3] END ..................C=5, gamma=0.0001, kernel=rbf; total time=14.4min\n",
      "[CV 3/3] END ......................C=10, gamma=1, kernel=rbf; total time=12.5min\n",
      "[CV 2/3] END ................C=10, gamma=0.01, kernel=linear; total time=12.0min\n",
      "[CV 1/3] END ..................C=10, gamma=0.001, kernel=rbf; total time=29.2min\n",
      "[CV 3/3] END .................C=10, gamma=0.0001, kernel=rbf; total time=14.9min\n",
      "[CV 2/3] END ...................C=100, gamma=0.1, kernel=rbf; total time=13.7min\n",
      "[CV 1/3] END ..............C=100, gamma=0.001, kernel=linear; total time=11.2min\n",
      "[CV 1/3] END .............C=100, gamma=0.0001, kernel=linear; total time=11.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....................C=0.1, gamma=1, kernel=rbf; total time=10.2min\n",
      "[CV 3/3] END ...............C=0.1, gamma=0.01, kernel=linear; total time=30.4min\n",
      "[CV 1/3] END ..............C=0.1, gamma=0.001, kernel=linear; total time=12.3min\n",
      "[CV 1/3] END .............C=0.1, gamma=0.0001, kernel=linear; total time=12.6min\n",
      "[CV 3/3] END ..................C=0.5, gamma=1, kernel=linear; total time=12.3min\n",
      "[CV 2/3] END ...................C=0.5, gamma=0.1, kernel=rbf; total time=15.4min\n",
      "[CV 3/3] END ..................C=0.5, gamma=0.01, kernel=rbf; total time=15.9min\n",
      "[CV 1/3] END ................C=0.5, gamma=0.0001, kernel=rbf; total time=86.8min\n",
      "[CV 3/3] END .......................C=1, gamma=1, kernel=rbf; total time=12.0min\n",
      "[CV 2/3] END ....................C=1, gamma=0.01, kernel=rbf; total time=15.2min\n",
      "[CV 1/3] END ...............C=1, gamma=0.0001, kernel=linear; total time=13.5min\n",
      "[CV 2/3] END ....................C=5, gamma=1, kernel=linear; total time=13.3min\n",
      "[CV 2/3] END ..................C=5, gamma=0.1, kernel=linear; total time=71.0min\n",
      "[CV 1/3] END ....................C=5, gamma=0.01, kernel=rbf; total time=12.0min\n",
      "[CV 3/3] END ...................C=5, gamma=0.001, kernel=rbf; total time=13.9min\n",
      "[CV 2/3] END ......................C=10, gamma=1, kernel=rbf; total time=12.2min\n",
      "[CV 1/3] END ................C=10, gamma=0.01, kernel=linear; total time=12.0min\n",
      "[CV 1/3] END ...............C=10, gamma=0.001, kernel=linear; total time=26.7min\n",
      "[CV 2/3] END ..............C=10, gamma=0.0001, kernel=linear; total time=10.7min\n",
      "[CV 2/3] END ..................C=100, gamma=1, kernel=linear; total time=10.5min\n",
      "[CV 3/3] END ................C=100, gamma=0.1, kernel=linear; total time=11.4min\n",
      "[CV 2/3] END ..................C=100, gamma=0.01, kernel=rbf; total time=14.9min\n",
      "[CV 3/3] END .............C=100, gamma=0.0001, kernel=linear; total time=27.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .................C=0.1, gamma=0.001, kernel=rbf; total time=18.2min\n",
      "[CV 2/3] END ..................C=0.5, gamma=1, kernel=linear; total time=15.6min\n",
      "[CV 1/3] END ...................C=0.5, gamma=0.1, kernel=rbf; total time=18.8min\n",
      "[CV 2/3] END ..............C=0.5, gamma=0.001, kernel=linear; total time=15.0min\n",
      "[CV 2/3] END ................C=0.5, gamma=0.0001, kernel=rbf; total time=89.4min\n",
      "[CV 2/3] END .....................C=1, gamma=0.1, kernel=rbf; total time=14.8min\n",
      "[CV 1/3] END ................C=1, gamma=0.001, kernel=linear; total time=16.4min\n",
      "[CV 2/3] END ..................C=1, gamma=0.0001, kernel=rbf; total time=21.7min\n",
      "[CV 1/3] END .....................C=5, gamma=0.1, kernel=rbf; total time=73.6min\n",
      "[CV 2/3] END ................C=5, gamma=0.001, kernel=linear; total time=10.8min\n",
      "[CV 1/3] END ..................C=5, gamma=0.0001, kernel=rbf; total time=15.8min\n",
      "[CV 1/3] END .................C=10, gamma=0.1, kernel=linear; total time=14.3min\n",
      "[CV 1/3] END ...................C=10, gamma=0.01, kernel=rbf; total time=30.8min\n",
      "[CV 1/3] END ..............C=10, gamma=0.0001, kernel=linear; total time=12.1min\n",
      "[CV 1/3] END .....................C=100, gamma=1, kernel=rbf; total time=12.8min\n",
      "[CV 3/3] END ...................C=100, gamma=0.1, kernel=rbf; total time=15.0min\n",
      "[CV 2/3] END .................C=100, gamma=0.001, kernel=rbf; total time=35.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/elizaveta/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=SVC(class_weight='balanced', max_iter=10000, tol=1e-06),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.5, 1, 5, 10, 100],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 0.5, 1, 5, 10, 100],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(class_weight='balanced', verbose=False, max_iter=10000, tol=1e-6,), \n",
    "                    param_grid, refit = True, verbose = 3, n_jobs=-1, cv=cv, scoring='roc_auc') \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_fulltrain, y_fulltrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e1b88f3-03b9-4f53-b76f-0c0ba30a769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=10, class_weight='balanced', gamma=1, max_iter=10000, tol=1e-06)\n",
      "0.9662165773120673\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_) \n",
    "print(grid.best_estimator_) \n",
    "print(grid.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7014c33-0f4a-4a5e-bd5e-154f144fb48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969138417976285"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "similarities = clf.decision_function(X_test)\n",
    "\n",
    "roc_auc_score(y_true = y_test, y_score = similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc03bb27-8608-41e7-a457-84ab15d6aca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/svm_v1.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, 'models/svm_v1.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b85c7d-fe68-4301-b403-771eee7a39e4",
   "metadata": {},
   "source": [
    "### Score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ca35cb1-6237-4e98-98a6-134d6e0461ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarities = pd.DataFrame(y_test, columns=['target', 'similarity'])\n",
    "df_similarities['similarity'] = similarities\n",
    "df_similarities['quantile_gr1'] = pd.qcut(df_similarities['similarity'], q=10)\n",
    "df_similarities['quantile_gr2'] = pd.cut(df_similarities['similarity'], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97729da4-01fb-46c6-80a6-e9ea4abe8202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_gr1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-4.008, -2.105]</th>\n",
       "      <td>0.466200</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-2.105, -1.808]</th>\n",
       "      <td>0.388500</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.808, -1.588]</th>\n",
       "      <td>0.311042</td>\n",
       "      <td>128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.588, -1.404]</th>\n",
       "      <td>0.077700</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.404, -1.233]</th>\n",
       "      <td>0.621601</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.233, -1.069]</th>\n",
       "      <td>0.466563</td>\n",
       "      <td>128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.069, -0.883]</th>\n",
       "      <td>1.165501</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.883, -0.627]</th>\n",
       "      <td>1.710731</td>\n",
       "      <td>128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.627, -0.0546]</th>\n",
       "      <td>7.226107</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.0546, 2.518]</th>\n",
       "      <td>78.865579</td>\n",
       "      <td>128700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target        \n",
       "                        mean   count\n",
       "quantile_gr1                        \n",
       "(-4.008, -2.105]    0.466200  128700\n",
       "(-2.105, -1.808]    0.388500  128700\n",
       "(-1.808, -1.588]    0.311042  128600\n",
       "(-1.588, -1.404]    0.077700  128700\n",
       "(-1.404, -1.233]    0.621601  128700\n",
       "(-1.233, -1.069]    0.466563  128600\n",
       "(-1.069, -0.883]    1.165501  128700\n",
       "(-0.883, -0.627]    1.710731  128600\n",
       "(-0.627, -0.0546]   7.226107  128700\n",
       "(-0.0546, 2.518]   78.865579  128700"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarities.groupby(['quantile_gr1']).agg({'target': ['mean', 'count']}) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c68038ff-c004-4cea-affd-c345c5ae267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_gr2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-4.014, -3.572]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-3.572, -3.137]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-3.137, -2.702]</th>\n",
       "      <td>1.204819</td>\n",
       "      <td>16600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-2.702, -2.267]</th>\n",
       "      <td>0.644122</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-2.267, -1.832]</th>\n",
       "      <td>0.305250</td>\n",
       "      <td>163800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.832, -1.397]</th>\n",
       "      <td>0.255195</td>\n",
       "      <td>274300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-1.397, -0.962]</th>\n",
       "      <td>0.615764</td>\n",
       "      <td>324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.962, -0.527]</th>\n",
       "      <td>1.751235</td>\n",
       "      <td>222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.527, -0.0922]</th>\n",
       "      <td>8.710801</td>\n",
       "      <td>86100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-0.0922, 0.343]</th>\n",
       "      <td>42.021277</td>\n",
       "      <td>37600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.343, 0.778]</th>\n",
       "      <td>80.398671</td>\n",
       "      <td>30100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.778, 1.213]</th>\n",
       "      <td>93.498452</td>\n",
       "      <td>32300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1.213, 1.648]</th>\n",
       "      <td>98.564593</td>\n",
       "      <td>20900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1.648, 2.083]</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2.083, 2.518]</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       target        \n",
       "                         mean   count\n",
       "quantile_gr2                         \n",
       "(-4.014, -3.572]     0.000000     500\n",
       "(-3.572, -3.137]     0.000000    3400\n",
       "(-3.137, -2.702]     1.204819   16600\n",
       "(-2.702, -2.267]     0.644122   62100\n",
       "(-2.267, -1.832]     0.305250  163800\n",
       "(-1.832, -1.397]     0.255195  274300\n",
       "(-1.397, -0.962]     0.615764  324800\n",
       "(-0.962, -0.527]     1.751235  222700\n",
       "(-0.527, -0.0922]    8.710801   86100\n",
       "(-0.0922, 0.343]    42.021277   37600\n",
       "(0.343, 0.778]      80.398671   30100\n",
       "(0.778, 1.213]      93.498452   32300\n",
       "(1.213, 1.648]      98.564593   20900\n",
       "(1.648, 2.083]     100.000000    8800\n",
       "(2.083, 2.518]     100.000000    2700"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarities.groupby(['quantile_gr2']).agg({'target': ['mean', 'count']}) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e1f85-6935-4cd1-8ef2-6e19b2caf591",
   "metadata": {},
   "source": [
    "### Final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "999dc9de-67b2-4e94-9393-922eb1589251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + exp(-x))\n",
    "\n",
    "def predict_proba(model, data):\n",
    "    return logistic(model.decision_function(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18fc6118-cc4b-4641-b27f-d50b68fe4699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test SVM accuracy:  0.96938\n",
      "Test SVM AUC-ROC: 0.96914\n",
      "Test SVM AUC-PR: 0.89268\n"
     ]
    }
   ],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "similarities = clf.decision_function(X_test)\n",
    "probs_test = logistic(similarities)\n",
    "\n",
    "print(f'Test SVM accuracy:  {accuracy_score(y_test, pred_test):.5f}')\n",
    "print(f'Test SVM AUC-ROC: {roc_auc_score(y_test, probs_test):.5f}')\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs_test)\n",
    "print(f'Test SVM AUC-PR: {auc(recall, precision):.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
